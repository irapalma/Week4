{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech_to_text.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irapalma/Week4/blob/main/speech_to_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speech to Text\n",
        "\n",
        "Part of your job is to produce a weekly summary (an intelligence report) of what is happening in your field. Sources of content include\n",
        "* Social Media\n",
        "* Webpages\n",
        "* YouTube\n",
        "* Podcasts\n",
        "* Blog posts\n",
        "* Reports\n",
        "* Articles\n",
        "\n",
        "I am sure you can think of many more. It would be great if we could write a program to create this report.\n",
        "\n",
        "There is a lot to do here. Gather the data, summarise the data and collate it into a document. How do we process video or a podcast? How can I get data from a webpage or a database? How can I summarise this data? Can I save the data as an excel spreadsheet or word document?\n",
        "\n",
        "A good strategy would be not to solve it all at once. Can we easily break it down into a few more straightforward problems? If we can solve and combine in the right way the simple issues, we should be able to solve the bigger problem. This approach of breaking a problem into subsystems is known as top-down design or programming. We look more closely at this approach in later modules.  \n",
        "\n",
        "Our general approach will be to take a source of content and convert that content into text. If needed, summarise the text and append it to our report. Then tidy up the information and submit it to our boss. Except for the last step, most of these steps can be done by a computer.\n",
        "\n",
        "Today, we will focus on how to convert an audio source into text. The audio source could be a podcast, a video or some other recording. We are going to convert speech to text. If you want to know more, have a look at [The Ultimate Guide to Speech Recognition With Python](https://realpython.com/python-speech-recognition/)\n",
        "\n",
        "## Tasks\n",
        "* Import into GitHub\n",
        "* Write a program to convert speech to text\n",
        "* regularly save to GitHub with a commit message"
      ],
      "metadata": {
        "id": "WTD7HkIDMXsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install SpeechRecognition\n"
      ],
      "metadata": {
        "id": "jpmIwK03SKOr",
        "outputId": "83e6f84b-1f49-4d4e-c3ee-304672184012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "sr.__version__\n",
        "'3.8.1'"
      ],
      "metadata": {
        "id": "wApn0aVUEZQ4",
        "outputId": "5a996d04-2361-4056-8617-631e6dbf90f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.8.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = sr.Recognizer()"
      ],
      "metadata": {
        "id": "_9oDjaghEndX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.recognize_google()"
      ],
      "metadata": {
        "id": "a7dYW9tKEp3O",
        "outputId": "dd883ef0-e73d-4ce5-d3d5-225c30646a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "recognize_legacy() missing 1 required positional argument: 'audio_data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d49a55a68619>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: recognize_legacy() missing 1 required positional argument: 'audio_data'"
          ]
        }
      ]
    }
  ]
}